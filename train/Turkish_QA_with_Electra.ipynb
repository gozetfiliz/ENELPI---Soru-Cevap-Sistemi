{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of electra-qa-training-gpu",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70e763d75783436f98e73b92f221a68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3bc0df2d7d84377a0b3151e28167da4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_baf07924506a4d65854ed7f390631251",
              "IPY_MODEL_3ff796bab4c6439c8c047da784c7e04c"
            ]
          }
        },
        "f3bc0df2d7d84377a0b3151e28167da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baf07924506a4d65854ed7f390631251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8be939d3f2a942b1a4648c096c9dd67d",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_538f8ff66f1c486aac9dd5f061036cd0"
          }
        },
        "3ff796bab4c6439c8c047da784c7e04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31c4385b080e4c7db215063c69c910bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [19:49&lt;00:00, 594.67s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ed721ac432941199ca59d4cd5d2dda4"
          }
        },
        "8be939d3f2a942b1a4648c096c9dd67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "538f8ff66f1c486aac9dd5f061036cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31c4385b080e4c7db215063c69c910bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ed721ac432941199ca59d4cd5d2dda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "add7ed3a1f1e454bb309e108c31ce3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a58cce00a0394b5ba39aa7d4f855c3ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3aaa0b9d8ab3454489681d9c525e008c",
              "IPY_MODEL_ad3f5e6f60884d94b299c14a1d8ac1be"
            ]
          }
        },
        "a58cce00a0394b5ba39aa7d4f855c3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3aaa0b9d8ab3454489681d9c525e008c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4053a61d9ae14ec2bdb83156ba891549",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 690,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 690,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_516de5a59f3b4f9297770486835cd87f"
          }
        },
        "ad3f5e6f60884d94b299c14a1d8ac1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42c4f10256b24b0eba4f7aaec94d8634",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 690/690 [09:54&lt;00:00,  1.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c60dc4c758cc4269af0cff4da089ad6f"
          }
        },
        "4053a61d9ae14ec2bdb83156ba891549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "516de5a59f3b4f9297770486835cd87f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42c4f10256b24b0eba4f7aaec94d8634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c60dc4c758cc4269af0cff4da089ad6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e89c2301873e4843be07bf1ad3a12aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_654fcf1e5c0f418cb62a9d72e576fe12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82d294e68d04460c8fce0e0e111d02bc",
              "IPY_MODEL_8259ad11333a478eb9f113450adbeff7"
            ]
          }
        },
        "654fcf1e5c0f418cb62a9d72e576fe12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82d294e68d04460c8fce0e0e111d02bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16567ea5d0064071b7b89c6bec719dc0",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 690,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 690,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8171b88b305249369cc4263a28eba5cd"
          }
        },
        "8259ad11333a478eb9f113450adbeff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec00cb3e0637465d8e17c2b521c958f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 690/690 [09:54&lt;00:00,  1.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69151a20690c4942bb72e913ea7bd471"
          }
        },
        "16567ea5d0064071b7b89c6bec719dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8171b88b305249369cc4263a28eba5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec00cb3e0637465d8e17c2b521c958f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69151a20690c4942bb72e913ea7bd471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e148bff3ca0b46c4946f299bca26b67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7f6b35cc0a747d6a66c6a3094b81d98",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f72501995e94867b6a58177c17cb69e",
              "IPY_MODEL_260e8e5dcb48484b9d7d7783b9cb81b5"
            ]
          }
        },
        "d7f6b35cc0a747d6a66c6a3094b81d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f72501995e94867b6a58177c17cb69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5bb70d5bf5504de2b601ddb21a1eeb7d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 473,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 473,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fccf4b17c4c421493c7ef62246cef75"
          }
        },
        "260e8e5dcb48484b9d7d7783b9cb81b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edd9d1195ce04209bad3aa29cd3ca80e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 473/473 [00:00&lt;00:00, 1.27kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ccc9121266344e9ba521f36f4c46192"
          }
        },
        "5bb70d5bf5504de2b601ddb21a1eeb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fccf4b17c4c421493c7ef62246cef75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edd9d1195ce04209bad3aa29cd3ca80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ccc9121266344e9ba521f36f4c46192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94d8985f7ead4b98a953699a368b6cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd0a1e4da8bd4c1c8009aa09a2043b91",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3045b7307925417ca68e1995923e9816",
              "IPY_MODEL_b717fef393c945d8827245caf6821e37"
            ]
          }
        },
        "fd0a1e4da8bd4c1c8009aa09a2043b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3045b7307925417ca68e1995923e9816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a84bc254ca42400e9af05aec5f578a58",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f71b4b04efb741ff8a586ff4ac4463a0"
          }
        },
        "b717fef393c945d8827245caf6821e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6aa009af504c4ad88b67f1f09a0f9482",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.91MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed01b169479f495bbc2d28b1c2351821"
          }
        },
        "a84bc254ca42400e9af05aec5f578a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f71b4b04efb741ff8a586ff4ac4463a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6aa009af504c4ad88b67f1f09a0f9482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed01b169479f495bbc2d28b1c2351821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d590b85b41249f7a2f94bb6b4e598af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3229cc984454d4184ddfeb71c9798cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac5060530b694684ba1672f4a38dd520",
              "IPY_MODEL_d48a76f0880e40a89ae4130a0572ce6a"
            ]
          }
        },
        "a3229cc984454d4184ddfeb71c9798cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac5060530b694684ba1672f4a38dd520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1953362ea4ec4e508c88c809d95b4928",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_701ad114db8c4ae7920610b804cd8b6d"
          }
        },
        "d48a76f0880e40a89ae4130a0572ce6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e2d51f66a794f8f89a52e240ac281aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 218B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_213c0c7e50ec44ccad09c44eb3406531"
          }
        },
        "1953362ea4ec4e508c88c809d95b4928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "701ad114db8c4ae7920610b804cd8b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e2d51f66a794f8f89a52e240ac281aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "213c0c7e50ec44ccad09c44eb3406531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "808f1677e8644f8e9d83598468fd4c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9a0b5c3ecbd4a62b31c4fb6d294115d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2bb0010a422c4496b27b5e5b3394a468",
              "IPY_MODEL_1a0c2ae6ab854c38b300a13a9bc80370"
            ]
          }
        },
        "c9a0b5c3ecbd4a62b31c4fb6d294115d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bb0010a422c4496b27b5e5b3394a468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_594f1ecaf17842f188834b7dae758e9f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 48,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84cdc3d798204a8a9323d65dfd6ac4cf"
          }
        },
        "1a0c2ae6ab854c38b300a13a9bc80370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c9e625cbbebc4ab0ad63f40c259dabde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 234B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd320da0ea3a4791a2519cbbe8932310"
          }
        },
        "594f1ecaf17842f188834b7dae758e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84cdc3d798204a8a9323d65dfd6ac4cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9e625cbbebc4ab0ad63f40c259dabde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd320da0ea3a4791a2519cbbe8932310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdd507357f7340aaa2dbb6f7708e2f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c93cf11766e448d81a4c9e23af963da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe95f6ba43e34109a84b9dd4952bee59",
              "IPY_MODEL_7f40987fe3744705be04571b70688104"
            ]
          }
        },
        "4c93cf11766e448d81a4c9e23af963da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe95f6ba43e34109a84b9dd4952bee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8b006cf206c4f39ab1bfd6b8dfec074",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435621774,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435621774,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81cb75f8d5814d94ac30b820157578dc"
          }
        },
        "7f40987fe3744705be04571b70688104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77eceb6e19994f289f924f178900f433",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:06&lt;00:00, 71.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_630c5077738c4de18c11e52b67838dac"
          }
        },
        "a8b006cf206c4f39ab1bfd6b8dfec074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81cb75f8d5814d94ac30b820157578dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77eceb6e19994f289f924f178900f433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "630c5077738c4de18c11e52b67838dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc29EYpN13cV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5fe3f55b-8e00-4825-f791-303964a7e3b8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 26 19:55:54 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDw0IXR18Vb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57ed1981-2d31-48ec-eeb7-4d8b36011698"
      },
      "source": [
        "#@title Install Apex\n",
        "# install apex to be able to use mix precision\n",
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v -q --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRL0oH6P2AQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "20c22048-aa6f-432e-b6cf-93804ccfcd85"
      },
      "source": [
        "!bash setup.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 7375 (delta 8), reused 0 (delta 0), pack-reused 7353\u001b[K\n",
            "Receiving objects: 100% (7375/7375), 13.89 MiB | 28.79 MiB/s, done.\n",
            "Resolving deltas: 100% (4979/4979), done.\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Processing ./apex\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptPupnLsfkMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "fe47f13f-a143-4fc5-fb75-a08f61466b2d"
      },
      "source": [
        "!pip install -U git+https://github.com/huggingface/transformers.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-agyu0u87\n",
            "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-agyu0u87\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 42.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (0.16.0)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.0.2-cp36-none-any.whl size=797698 sha256=4773209165b163982ab0c6c1d2d37af4b9e5f398bc61e05e41374983fd355d4a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rrpqt4jo/wheels/33/eb/3b/4bf5dd835e865e472d4fc0754f35ac0edb08fe852e8f21655f\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=75162d72a170560bd64700d217fea4414d1d73926a317d1ecdf9a23bc80bc64e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gqe_FsJy7jf",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_zVHNwQy-nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import time\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from filelock import FileLock\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "from transformers.modeling_auto import MODEL_FOR_QUESTION_ANSWERING_MAPPING\n",
        "from transformers.tokenization_utils import PreTrainedTokenizer\n",
        "from transformers.data.processors.squad import SquadFeatures, SquadV1Processor, SquadV2Processor, squad_convert_examples_to_features\n",
        "from transformers.data.data_collator import DataCollator\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_FOR_QUESTION_ANSWERING_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SquadDataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    model_type: str = field(\n",
        "        default=None, metadata={\"help\": \"Model type selected in the list: \" + \", \".join(MODEL_TYPES)}\n",
        "    )\n",
        "    data_dir: str = field(\n",
        "        default=None, metadata={\"help\": \"The input data dir. Should contain the .json files for the SQuAD task.\"}\n",
        "    )\n",
        "    max_seq_length: int = field(\n",
        "        default=128,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "            \"than this will be truncated, sequences shorter will be padded.\"\n",
        "        },\n",
        "    )\n",
        "    doc_stride: int = field(\n",
        "        default=128,\n",
        "        metadata={\"help\": \"When splitting up a long document into chunks, how much stride to take between chunks.\"},\n",
        "    )\n",
        "    max_query_length: int = field(\n",
        "        default=64,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum number of tokens for the question. Questions longer than this will \"\n",
        "            \"be truncated to this length.\"\n",
        "        },\n",
        "    )\n",
        "    max_answer_length: int = field(\n",
        "        default=30,\n",
        "        metadata={\n",
        "            \"help\": \"The maximum length of an answer that can be generated. This is needed because the start \"\n",
        "            \"and end predictions are not conditioned on one another.\"\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
        "    )\n",
        "    version_2_with_negative: bool = field(\n",
        "        default=False, metadata={\"help\": \"If true, the SQuAD examples contain some that do not have an answer.\"}\n",
        "    )\n",
        "    null_score_diff_threshold: float = field(\n",
        "        default=0.0, metadata={\"help\": \"If null_score - best_non_null is greater than the threshold predict null.\"}\n",
        "    )\n",
        "    n_best_size: int = field(\n",
        "        default=20, metadata={\"help\": \"If null_score - best_non_null is greater than the threshold predict null.\"}\n",
        "    )\n",
        "    lang_id: int = field(\n",
        "        default=0,\n",
        "        metadata={\n",
        "            \"help\": \"language id of input for language-specific xlm models (see tokenization_xlm.PRETRAINED_INIT_CONFIGURATION)\"\n",
        "        },\n",
        "    )\n",
        "    threads: int = field(default=1, metadata={\"help\": \"multiple threads for converting example to features\"})\n",
        "\n",
        "\n",
        "class Split(Enum):\n",
        "    train = \"train\"\n",
        "    dev = \"dev\"\n",
        "\n",
        "\n",
        "class SquadDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This will be superseded by a framework-agnostic approach\n",
        "    soon.\n",
        "    \"\"\"\n",
        "\n",
        "    args: SquadDataTrainingArguments\n",
        "    features: List[SquadFeatures]\n",
        "    mode: Split\n",
        "    is_language_sensitive: bool\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        args: SquadDataTrainingArguments,\n",
        "        tokenizer: PreTrainedTokenizer,\n",
        "        limit_length: Optional[int] = None,\n",
        "        mode: Union[str, Split] = Split.train,\n",
        "        is_language_sensitive: Optional[bool] = False,\n",
        "        cache_dir: Optional[str] = None,\n",
        "    ):\n",
        "        self.args = args\n",
        "        self.is_language_sensitive = is_language_sensitive\n",
        "        self.processor = SquadV2Processor() if args.version_2_with_negative else SquadV1Processor()\n",
        "        if isinstance(mode, str):\n",
        "            try:\n",
        "                mode = Split[mode]\n",
        "            except KeyError:\n",
        "                raise KeyError(\"mode is not a valid split name\")\n",
        "        self.mode = mode\n",
        "        # Load data features from cache or dataset file\n",
        "        cached_features_file = os.path.join(\n",
        "            cache_dir if cache_dir is not None else args.data_dir,\n",
        "            \"cached_{}_{}_{}\".format(mode.value, tokenizer.__class__.__name__, str(args.max_seq_length),),\n",
        "        )\n",
        "\n",
        "        # Make sure only the first process in distributed training processes the dataset,\n",
        "        # and the others will use the cache.\n",
        "        lock_path = cached_features_file + \".lock\"\n",
        "        with FileLock(lock_path):\n",
        "            if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
        "                start = time.time()\n",
        "                self.features = torch.load(cached_features_file)\n",
        "                logger.info(\n",
        "                    f\"Loading features from cached file {cached_features_file} [took %.3f s]\", time.time() - start\n",
        "                )\n",
        "            else:\n",
        "                if mode == Split.dev:\n",
        "                    examples = self.processor.get_dev_examples(args.data_dir)\n",
        "                else:\n",
        "                    examples = self.processor.get_train_examples(args.data_dir)\n",
        "\n",
        "                self.features = squad_convert_examples_to_features(\n",
        "                    examples=examples,\n",
        "                    tokenizer=tokenizer,\n",
        "                    max_seq_length=args.max_seq_length,\n",
        "                    doc_stride=args.doc_stride,\n",
        "                    max_query_length=args.max_query_length,\n",
        "                    is_training=mode == Split.train,\n",
        "                    threads=args.threads,\n",
        "                )\n",
        "\n",
        "                start = time.time()\n",
        "                torch.save(self.features, cached_features_file)\n",
        "                # ^ This seems to take a lot of time so I want to investigate why and how we can improve.\n",
        "                logger.info(\n",
        "                    \"Saving features into cached file %s [took %.3f s]\", cached_features_file, time.time() - start\n",
        "                )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
        "        # Convert to Tensors and build dataset\n",
        "        feature = self.features[i]\n",
        "\n",
        "        input_ids = torch.tensor(feature.input_ids, dtype=torch.long)\n",
        "        attention_mask = torch.tensor(feature.attention_mask, dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(feature.token_type_ids, dtype=torch.long)\n",
        "        cls_index = torch.tensor(feature.cls_index, dtype=torch.long)\n",
        "        p_mask = torch.tensor(feature.p_mask, dtype=torch.float)\n",
        "        is_impossible = torch.tensor(feature.is_impossible, dtype=torch.float)\n",
        "\n",
        "        inputs = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"token_type_ids\": token_type_ids,\n",
        "        }\n",
        "\n",
        "        if self.args.model_type in [\"xlm\", \"roberta\", \"distilbert\", \"camembert\"]:\n",
        "            del inputs[\"token_type_ids\"]\n",
        "\n",
        "        if self.args.model_type in [\"xlnet\", \"xlm\"]:\n",
        "            inputs.update({\"cls_index\": cls_index, \"p_mask\": p_mask})\n",
        "            if self.args.version_2_with_negative:\n",
        "                inputs.update({\"is_impossible\": is_impossible})\n",
        "            if self.is_language_sensitive:\n",
        "                inputs.update({\"langs\": (torch.ones(input_ids.shape, dtype=torch.int64) * self.args.lang_id)})\n",
        "\n",
        "        if self.mode == Split.train:\n",
        "            start_positions = torch.tensor(feature.start_position, dtype=torch.long)\n",
        "            end_positions = torch.tensor(feature.end_position, dtype=torch.long)\n",
        "            inputs.update({\"start_positions\": start_positions, \"end_positions\": end_positions})\n",
        "\n",
        "        return inputs\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForQuestionAnswering:\n",
        "    \"\"\"\n",
        "    Data collator used for language modeling.\n",
        "    - collates batches of tensors\n",
        "    - preprocesses batches for question answering\n",
        "    \"\"\"\n",
        "\n",
        "    def collate_batch(self, batch: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
        "        keys = batch[0].keys()\n",
        "        inputs = {}\n",
        "\n",
        "        for key in keys:\n",
        "            inputs[key] = torch.stack([example[key] for example in batch])\n",
        "\n",
        "        return inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tty8vuMBqI5L",
        "colab_type": "text"
      },
      "source": [
        "## Write training script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdmKlMkfcLa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dataclasses\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    ElectraConfig,\n",
        "    ElectraForQuestionAnswering,\n",
        "    ElectraTokenizer,\n",
        "    HfArgumentParser,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name_or_path: str = field(\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "    )\n",
        "    tokenizer_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
        "    )\n",
        "    config_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
        "    )\n",
        "\n",
        "\n",
        "def main():\n",
        "    # See all possible arguments in src/transformers/training_args.py\n",
        "    # or by passing the --help flag to this script.\n",
        "    # We now keep distinct sets of args, for a cleaner separation of concerns.\n",
        "\n",
        "    parser = HfArgumentParser((ModelArguments, SquadDataTrainingArguments, TrainingArguments))\n",
        "\n",
        "    model_args, data_args, training_args = parser.parse_json_file(json_file='./args.json')\n",
        "\n",
        "    if (\n",
        "        os.path.exists(training_args.output_dir)\n",
        "        and os.listdir(training_args.output_dir)\n",
        "        and training_args.do_train\n",
        "        and not training_args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
        "        )\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        training_args.local_rank,\n",
        "        training_args.device,\n",
        "        training_args.n_gpu,\n",
        "        bool(training_args.local_rank != -1),\n",
        "        training_args.fp16,\n",
        "    )\n",
        "    logger.info(\"Training/evaluation parameters %s\", training_args)\n",
        "\n",
        "    # Prepare Question-Answering task\n",
        "    # Load pretrained model and tokenizer\n",
        "    #\n",
        "    # Distributed training:\n",
        "    # The .from_pretrained methods guarantee that only one local process can concurrently\n",
        "    # download model & vocab.\n",
        "\n",
        "    config = ElectraConfig.from_pretrained(\n",
        "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "    )\n",
        "    tokenizer = ElectraTokenizer.from_pretrained(\n",
        "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "    )\n",
        "    model = ElectraForQuestionAnswering.from_pretrained(\n",
        "        model_args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
        "        config=config,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "    )\n",
        "\n",
        "    # Get datasets\n",
        "    is_language_sensitive = hasattr(model.config, \"lang2id\")\n",
        "    train_dataset = (\n",
        "        SquadDataset(\n",
        "            data_args, tokenizer=tokenizer, is_language_sensitive=is_language_sensitive, cache_dir=model_args.cache_dir\n",
        "        )\n",
        "        if training_args.do_train\n",
        "        else None\n",
        "    )\n",
        "    eval_dataset = (\n",
        "        SquadDataset(\n",
        "            data_args,\n",
        "            tokenizer=tokenizer,\n",
        "            mode=\"dev\",\n",
        "            is_language_sensitive=is_language_sensitive,\n",
        "            cache_dir=model_args.cache_dir,\n",
        "        )\n",
        "        if training_args.do_eval\n",
        "        else None\n",
        "    )\n",
        "    data_collator = DataCollatorForQuestionAnswering()\n",
        "\n",
        "    # Initialize our Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    if training_args.do_train:\n",
        "        trainer.train(\n",
        "            model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
        "        )\n",
        "        trainer.save_model()\n",
        "        # For convenience, we also re-save the tokenizer to the same directory,\n",
        "        # so that you can share your model easily on huggingface.co/models =)\n",
        "        if trainer.is_world_master():\n",
        "            tokenizer.save_pretrained(training_args.output_dir)\n",
        "\n",
        "\n",
        "def _mp_fn(index):\n",
        "    # For xla_spawn (TPUs)\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15duw24hqMBy",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUkR6G1v2bvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "3a42de34-db48-48f5-e67e-eff0186cf83d"
      },
      "source": [
        "!mkdir squad_data\n",
        "%cd squad_data\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/squad_data\n",
            "--2020-07-26 20:08:53--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.108.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: â€˜train-v1.1.jsonâ€™\n",
            "\n",
            "train-v1.1.json     100%[===================>]  28.88M  47.0MB/s    in 0.6s    \n",
            "\n",
            "2020-07-26 20:08:54 (47.0 MB/s) - â€˜train-v1.1.jsonâ€™ saved [30288272/30288272]\n",
            "\n",
            "--2020-07-26 20:08:56--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.111.153, 185.199.108.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4854279 (4.6M) [application/json]\n",
            "Saving to: â€˜dev-v1.1.jsonâ€™\n",
            "\n",
            "dev-v1.1.json       100%[===================>]   4.63M  16.7MB/s    in 0.3s    \n",
            "\n",
            "2020-07-26 20:08:56 (16.7 MB/s) - â€˜dev-v1.1.jsonâ€™ saved [4854279/4854279]\n",
            "\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1I6IhBM1KV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOvs9RUllLTw",
        "colab_type": "text"
      },
      "source": [
        "Let's write the arguments in a dict and store in a json file. The above code will load this file and parse the arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ObtXlBVuJqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args_dict = {\n",
        "  \"model_name_or_path\"          : \"dbmdz/electra-base-turkish-cased-discriminator\",\n",
        "  \"tokenizer_name\"              : \"dbmdz/electra-base-turkish-cased-discriminator\",\n",
        "  \"model_type\"                  : \"electra\",\n",
        "  \"data_dir\"                    : \"./squad_data\",\n",
        "  \"max_seq_length\"              : 512 ,\n",
        "  \"doc_stride\"                  : 128,\n",
        "  \"fp16\"                        : True,\n",
        "  \"max_grad_norm\"               : 0.5,\n",
        "  \"per_device_train_batch_size\" : 16,\n",
        "  \"per_device_eval_batch_size\"  : 16,\n",
        "  \"gradient_accumulation_steps\" : 8,\n",
        "  \"logging_steps\"               : 50,\n",
        "  \"learning_rate\"               : 3e-5,\n",
        "  \"num_train_epochs\"            : 2,\n",
        "  \"overwrite_output_dir\"        : True,\n",
        "  \"output_dir\"                  : \"./electra-base-discriminator-finetuned_squadv1_tr\",\n",
        "  \"do_train\"                    : True,\n",
        "  \"do_eval\"                     : True\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU5MI8ju1L3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('args.json', 'w') as f:\n",
        "  json.dump(args_dict, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsQB1Kpjlltp",
        "colab_type": "text"
      },
      "source": [
        "Start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbFNc_YR4hF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70e763d75783436f98e73b92f221a68f",
            "f3bc0df2d7d84377a0b3151e28167da4",
            "baf07924506a4d65854ed7f390631251",
            "3ff796bab4c6439c8c047da784c7e04c",
            "8be939d3f2a942b1a4648c096c9dd67d",
            "538f8ff66f1c486aac9dd5f061036cd0",
            "31c4385b080e4c7db215063c69c910bd",
            "2ed721ac432941199ca59d4cd5d2dda4",
            "add7ed3a1f1e454bb309e108c31ce3f7",
            "a58cce00a0394b5ba39aa7d4f855c3ee",
            "3aaa0b9d8ab3454489681d9c525e008c",
            "ad3f5e6f60884d94b299c14a1d8ac1be",
            "4053a61d9ae14ec2bdb83156ba891549",
            "516de5a59f3b4f9297770486835cd87f",
            "42c4f10256b24b0eba4f7aaec94d8634",
            "c60dc4c758cc4269af0cff4da089ad6f",
            "e89c2301873e4843be07bf1ad3a12aa6",
            "654fcf1e5c0f418cb62a9d72e576fe12",
            "82d294e68d04460c8fce0e0e111d02bc",
            "8259ad11333a478eb9f113450adbeff7",
            "16567ea5d0064071b7b89c6bec719dc0",
            "8171b88b305249369cc4263a28eba5cd",
            "ec00cb3e0637465d8e17c2b521c958f7",
            "69151a20690c4942bb72e913ea7bd471"
          ]
        },
        "outputId": "b8b3e3bc-e1b8-4da8-8b59-272a14dacc56"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:17:50 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
            "07/26/2020 20:17:50 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "07/26/2020 20:17:50 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./electra-base-discriminator-finetuned_squadv1_tr', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=8, learning_rate=3e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=0.5, num_train_epochs=2, max_steps=-1, warmup_steps=0, logging_dir='runs/Jul26_20-17-50_5ae585319611', logging_first_step=False, logging_steps=50, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, past_index=-1)\n",
            "07/26/2020 20:17:50 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/electra-base-turkish-cased-discriminator/config.json from cache at /root/.cache/torch/transformers/f8b668417b824a389a6f3515d2bd2fdd023c5d8d121b26f2063d7fe993404a09.45a53a5013547a919bb8542889f059b997e00eadd327a67d4406c4834982e597\n",
            "07/26/2020 20:17:50 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "07/26/2020 20:17:50 - INFO - transformers.tokenization_utils_base -   Model name 'dbmdz/electra-base-turkish-cased-discriminator' not found in model shortcut name list (google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). Assuming 'dbmdz/electra-base-turkish-cased-discriminator' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "07/26/2020 20:17:51 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/electra-base-turkish-cased-discriminator/vocab.txt from cache at /root/.cache/torch/transformers/fe6b185644da3bc4b3edb582b707fa401670ce50a9a61d1a1c4d4f6712eb2fad.0df1d64abb373fc32402d72e6d347e1774e92e397d4dba7ee272c82288d22542\n",
            "07/26/2020 20:17:51 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/electra-base-turkish-cased-discriminator/added_tokens.json from cache at None\n",
            "07/26/2020 20:17:51 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/electra-base-turkish-cased-discriminator/special_tokens_map.json from cache at None\n",
            "07/26/2020 20:17:51 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/electra-base-turkish-cased-discriminator/tokenizer_config.json from cache at /root/.cache/torch/transformers/236f22f0cbf58bd9ea3f5086944b3db39b60b5501dc7b7dd7cd5cad840751625.6bc333f81de76eefa436f7c9d2a166cdfd8cc6be6e0f58ab6c7a24f61417f955\n",
            "07/26/2020 20:17:51 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/dbmdz/electra-base-turkish-cased-discriminator/tokenizer.json from cache at None\n",
            "07/26/2020 20:17:51 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/dbmdz/electra-base-turkish-cased-discriminator/pytorch_model.bin from cache at /root/.cache/torch/transformers/bfda929622378d6539183ec16fceb53f1567be2e925e7769f6e166c9077facac.4ec6eebbdbe31e8d6ca48964a4552d1063a65c64f2b5f0be0a83d071d8b28080\n",
            "07/26/2020 20:17:54 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at dbmdz/electra-base-turkish-cased-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "07/26/2020 20:17:54 - WARNING - transformers.modeling_utils -   Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at dbmdz/electra-base-turkish-cased-discriminator and are newly initialized: ['electra.embeddings.position_ids', 'qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "07/26/2020 20:17:54 - INFO - filelock -   Lock 139739097923200 acquired on ./squad_data/cached_train_ElectraTokenizer_512.lock\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 681/681 [00:03<00:00, 202.21it/s]\n",
            "convert squad examples to features:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4033/8308 [00:54<00:20, 210.39it/s]07/26/2020 20:18:52 - WARNING - transformers.data.processors.squad -   Could not find answer: '' vs. 'Yahudi'\n",
            "convert squad examples to features:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4065/8308 [00:54<00:20, 212.13it/s]07/26/2020 20:18:52 - WARNING - transformers.data.processors.squad -   Could not find answer: '' vs. 'Salisik asit, krizarobin ve iyodun, Ã¶ÄŸrencisi Hulusi BehÃ§et ile birlikte de sÃ¼blimenin'\n",
            "convert squad examples to features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8308/8308 [01:23<00:00, 99.50it/s] \n",
            "add example index and unique id: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8308/8308 [00:00<00:00, 733544.07it/s]\n",
            "07/26/2020 20:19:35 - INFO - __main__ -   Saving features into cached file ./squad_data/cached_train_ElectraTokenizer_512 [took 13.516 s]\n",
            "07/26/2020 20:19:35 - INFO - filelock -   Lock 139739097923200 released on ./squad_data/cached_train_ElectraTokenizer_512.lock\n",
            "07/26/2020 20:19:35 - INFO - filelock -   Lock 139739096501664 acquired on ./squad_data/cached_dev_ElectraTokenizer_512.lock\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 171.88it/s]\n",
            "convert squad examples to features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 892/892 [00:13<00:00, 65.06it/s]\n",
            "add example index and unique id: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 892/892 [00:00<00:00, 417977.79it/s]\n",
            "07/26/2020 20:19:52 - INFO - __main__ -   Saving features into cached file ./squad_data/cached_dev_ElectraTokenizer_512 [took 2.078 s]\n",
            "07/26/2020 20:19:52 - INFO - filelock -   Lock 139739096501664 released on ./squad_data/cached_dev_ElectraTokenizer_512.lock\n",
            "07/26/2020 20:20:07 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:226: FutureWarning: The `data_collator` should now be a simple callable (function, class with `__call__`), classes with a `collate_batch` are deprecated and won't be supported in a future version.\n",
            "  FutureWarning,\n",
            "07/26/2020 20:20:07 - INFO - transformers.trainer -   ***** Running training *****\n",
            "07/26/2020 20:20:07 - INFO - transformers.trainer -     Num examples = 11038\n",
            "07/26/2020 20:20:07 - INFO - transformers.trainer -     Num Epochs = 2\n",
            "07/26/2020 20:20:07 - INFO - transformers.trainer -     Instantaneous batch size per device = 16\n",
            "07/26/2020 20:20:07 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "07/26/2020 20:20:08 - INFO - transformers.trainer -     Gradient Accumulation steps = 8\n",
            "07/26/2020 20:20:08 - INFO - transformers.trainer -     Total optimization steps = 172\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70e763d75783436f98e73b92f221a68f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='iâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "add7ed3a1f1e454bb309e108c31ce3f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=690.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "07/26/2020 20:25:53 - INFO - transformers.trainer -   {'loss': 4.617739557027817, 'learning_rate': 2.1279069767441862e-05, 'epoch': 0.5797101449275363, 'step': 50}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e89c2301873e4843be07bf1ad3a12aa6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=690.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:31:39 - INFO - transformers.trainer -   {'loss': 2.367682585120201, 'learning_rate': 1.2558139534883723e-05, 'epoch': 1.1623188405797102, 'step': 100}\n",
            "07/26/2020 20:37:24 - INFO - transformers.trainer -   {'loss': 1.7186071726679801, 'learning_rate': 3.837209302325582e-06, 'epoch': 1.7420289855072464, 'step': 150}\n",
            "07/26/2020 20:39:57 - INFO - transformers.trainer -   \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "07/26/2020 20:39:57 - INFO - transformers.trainer -   Saving model checkpoint to ./electra-base-discriminator-finetuned_squadv1_tr\n",
            "07/26/2020 20:39:57 - INFO - transformers.configuration_utils -   Configuration saved in ./electra-base-discriminator-finetuned_squadv1_tr/config.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:39:57 - INFO - transformers.modeling_utils -   Model weights saved in ./electra-base-discriminator-finetuned_squadv1_tr/pytorch_model.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APL3nsMN5Aiq",
        "colab_type": "text"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gJXVTGB5C8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "deaa2c94-9274-4195-aac3-bdc105c65727"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-26 20:40:22--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34287 (33K) [text/plain]\n",
            "Saving to: â€˜run_squad.pyâ€™\n",
            "\n",
            "\rrun_squad.py          0%[                    ]       0  --.-KB/s               \rrun_squad.py        100%[===================>]  33.48K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-07-26 20:40:22 (2.80 MB/s) - â€˜run_squad.pyâ€™ saved [34287/34287]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne9aO1fI5DC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09022d64-b2c1-4368-8d0e-6f8ec88e99f5"
      },
      "source": [
        "!python run_squad.py \\\n",
        "--model_type electra \\\n",
        "--model_name_or_path electra-base-discriminator-finetuned_squadv1_tr \\\n",
        "--do_eval \\\n",
        "--data_dir ./squad_data \\\n",
        "--cache_dir ./squad_data \\\n",
        "--per_gpu_train_batch_size 16 \\\n",
        "--max_seq_length 512 \\\n",
        "--doc_stride 128 \\\n",
        "--output_dir ./squad_data \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-26 20:41:07.421800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "07/26/2020 20:41:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "07/26/2020 20:41:09 - INFO - transformers.configuration_utils -   loading configuration file electra-base-discriminator-finetuned_squadv1_tr/config.json\n",
            "07/26/2020 20:41:09 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"ElectraForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "07/26/2020 20:41:09 - INFO - transformers.configuration_utils -   loading configuration file electra-base-discriminator-finetuned_squadv1_tr/config.json\n",
            "07/26/2020 20:41:09 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"ElectraForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   Model name 'electra-base-discriminator-finetuned_squadv1_tr' not found in model shortcut name list (google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). Assuming 'electra-base-discriminator-finetuned_squadv1_tr' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   Didn't find file electra-base-discriminator-finetuned_squadv1_tr/added_tokens.json. We won't load it.\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   Didn't find file electra-base-discriminator-finetuned_squadv1_tr/tokenizer.json. We won't load it.\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   loading file electra-base-discriminator-finetuned_squadv1_tr/vocab.txt\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   loading file None\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   loading file electra-base-discriminator-finetuned_squadv1_tr/special_tokens_map.json\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   loading file electra-base-discriminator-finetuned_squadv1_tr/tokenizer_config.json\n",
            "07/26/2020 20:41:09 - INFO - transformers.tokenization_utils_base -   loading file None\n",
            "07/26/2020 20:41:09 - INFO - transformers.modeling_utils -   loading weights file electra-base-discriminator-finetuned_squadv1_tr/pytorch_model.bin\n",
            "07/26/2020 20:41:12 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing ElectraForQuestionAnswering.\n",
            "\n",
            "07/26/2020 20:41:12 - INFO - transformers.modeling_utils -   All the weights of ElectraForQuestionAnswering were initialized from the model checkpoint at electra-base-discriminator-finetuned_squadv1_tr.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use ElectraForQuestionAnswering for predictions without further training.\n",
            "07/26/2020 20:41:15 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='./squad_data', config_name='', data_dir='./squad_data', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, lang_id=0, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=512, max_steps=-1, model_name_or_path='electra-base-discriminator-finetuned_squadv1_tr', model_type='electra', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='./squad_data', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=16, predict_file=None, save_steps=500, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)\n",
            "07/26/2020 20:41:15 - INFO - __main__ -   Loading checkpoint electra-base-discriminator-finetuned_squadv1_tr for evaluation\n",
            "07/26/2020 20:41:15 - INFO - __main__ -   Evaluate the following checkpoints: ['electra-base-discriminator-finetuned_squadv1_tr']\n",
            "07/26/2020 20:41:15 - INFO - transformers.configuration_utils -   loading configuration file electra-base-discriminator-finetuned_squadv1_tr/config.json\n",
            "07/26/2020 20:41:15 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"ElectraForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "07/26/2020 20:41:15 - INFO - transformers.modeling_utils -   loading weights file electra-base-discriminator-finetuned_squadv1_tr/pytorch_model.bin\n",
            "07/26/2020 20:41:18 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing ElectraForQuestionAnswering.\n",
            "\n",
            "07/26/2020 20:41:18 - INFO - transformers.modeling_utils -   All the weights of ElectraForQuestionAnswering were initialized from the model checkpoint at electra-base-discriminator-finetuned_squadv1_tr.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use ElectraForQuestionAnswering for predictions without further training.\n",
            "07/26/2020 20:41:18 - INFO - __main__ -   Creating features from dataset file at ./squad_data\n",
            "100% 72/72 [00:00<00:00, 171.46it/s]\n",
            "convert squad examples to features: 100% 892/892 [00:13<00:00, 65.89it/s]\n",
            "add example index and unique id: 100% 892/892 [00:00<00:00, 668809.29it/s]\n",
            "07/26/2020 20:41:33 - INFO - __main__ -   Saving features into cached file ./squad_data/cached_dev_electra-base-discriminator-finetuned_squadv1_tr_512\n",
            "07/26/2020 20:41:35 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "07/26/2020 20:41:35 - INFO - __main__ -     Num examples = 1564\n",
            "07/26/2020 20:41:35 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 196/196 [00:27<00:00,  7.13it/s]\n",
            "07/26/2020 20:42:03 - INFO - __main__ -     Evaluation done in total 27.476275 secs (0.017568 sec per example)\n",
            "07/26/2020 20:42:03 - INFO - transformers.data.metrics.squad_metrics -   Writing predictions to: ./squad_data/predictions_.json\n",
            "07/26/2020 20:42:03 - INFO - transformers.data.metrics.squad_metrics -   Writing nbest to: ./squad_data/nbest_predictions_.json\n",
            "07/26/2020 20:42:06 - INFO - __main__ -   Results: {'exact': 44.05829596412556, 'f1': 67.81915142395991, 'total': 892, 'HasAns_exact': 44.05829596412556, 'HasAns_f1': 67.81915142395991, 'HasAns_total': 892, 'best_exact': 44.05829596412556, 'best_exact_thresh': 0.0, 'best_f1': 67.81915142395991, 'best_f1_thresh': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNeFgo_Z9HgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc955996-00b9-4ad0-a09f-dfe2f72dd463"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./electra-base-discriminator-finetuned_squadv1_tr/\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"./electra-base-discriminator-finetuned_squadv1_tr/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:53:41 - INFO - transformers.configuration_utils -   loading configuration file ./electra-base-discriminator-finetuned_squadv1_tr/config.json\n",
            "07/26/2020 20:53:41 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"ElectraForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   Model name './electra-base-discriminator-finetuned_squadv1_tr/' not found in model shortcut name list (google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). Assuming './electra-base-discriminator-finetuned_squadv1_tr/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   Didn't find file ./electra-base-discriminator-finetuned_squadv1_tr/added_tokens.json. We won't load it.\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   Didn't find file ./electra-base-discriminator-finetuned_squadv1_tr/tokenizer.json. We won't load it.\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   loading file ./electra-base-discriminator-finetuned_squadv1_tr/vocab.txt\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   loading file None\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   loading file ./electra-base-discriminator-finetuned_squadv1_tr/special_tokens_map.json\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   loading file ./electra-base-discriminator-finetuned_squadv1_tr/tokenizer_config.json\n",
            "07/26/2020 20:53:41 - INFO - transformers.tokenization_utils_base -   loading file None\n",
            "07/26/2020 20:53:41 - INFO - transformers.configuration_utils -   loading configuration file ./electra-base-discriminator-finetuned_squadv1_tr/config.json\n",
            "07/26/2020 20:53:41 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"ElectraForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "07/26/2020 20:53:41 - INFO - transformers.modeling_utils -   loading weights file ./electra-base-discriminator-finetuned_squadv1_tr/pytorch_model.bin\n",
            "07/26/2020 20:53:44 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing ElectraForQuestionAnswering.\n",
            "\n",
            "07/26/2020 20:53:44 - INFO - transformers.modeling_utils -   All the weights of ElectraForQuestionAnswering were initialized from the model checkpoint at ./electra-base-discriminator-finetuned_squadv1_tr/.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use ElectraForQuestionAnswering for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RjkDtEaFklR",
        "colab_type": "text"
      },
      "source": [
        "## Model in action ðŸš€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d_BTfFjFy8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2fefdb1a-e1b2-430d-e857-04f6715f27ab"
      },
      "source": [
        "\n",
        "def ask_question(question,context):\n",
        "  inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\") \n",
        "\n",
        "\n",
        "  answer_start_scores, answer_end_scores = model(**inputs)\n",
        "  answer_start = torch.argmax(answer_start_scores)  \n",
        "  answer_end = torch.argmax(answer_end_scores) + 1  \n",
        "  return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
        "\n",
        "question = \"OsmanlÄ±larÄ±n balkanlarda haÃ§lÄ±larla yaptÄ±ÄŸÄ± ilk savaÅŸ hangisidir?\"\n",
        "context = \"\"\"I.Murat 1326 yÄ±lÄ±nda Bursada doÄŸmuÅŸtur. I.Murat 1389 yÄ±lÄ±nda Kosavada Ã¶lmÃ¼ÅŸtÃ¼r.\n",
        "    OsmanlÄ± Ä°mparatorluÄŸu'nun Ã¼Ã§Ã¼ncÃ¼ padiÅŸahÄ± olan I.Murat, 1359 ile 1389 yÄ±llarÄ± arasÄ±nda beylik yapmÄ±ÅŸtÄ±r.\n",
        "    I.Murat'Ä±n babasÄ± Orhan Gazi, annesi NilÃ¼fer Hatun'dur.\n",
        "    I.Murat babasÄ± Orhan Gazi dÃ¶neminde 95.000 kilometrekare olarak almÄ±ÅŸ, devlet topraklarÄ±nÄ± I.Murat dÃ¶neminde topraklarÄ±nÄ± yaklaÅŸÄ±k 500.000 kilometrekareye geniÅŸlemiÅŸtir.\n",
        "    1362 yÄ±lÄ±nda Ankara Eratna beyliÄŸinden yeniden alÄ±nmÄ±ÅŸtÄ±r.\n",
        "    1362 yÄ±lÄ±nda SazlÄ±dere savaÅŸÄ± ile gerÃ§ekleÅŸmiÅŸtir. SazlÄ±dere savaÅŸÄ± sonucunda Edirne ve Filibe alÄ±nmÄ±ÅŸtÄ±r. SazlÄ±dere savaÅŸÄ± OsmanlÄ± devleti ile Bizans ve Bulgar gÃ¼Ã§leri arasÄ±nda gerÃ§ekleÅŸmiÅŸtir.\n",
        "    HamitoÄŸullarÄ±ndan EÄŸridir ve Ã§evresi satÄ±n alÄ±ndÄ±.\n",
        "    1364 yÄ±lÄ±nda SÄ±rpsÄ±ndÄ±ÄŸÄ± savaÅŸÄ± gerÃ§ekleÅŸti. Balkan devletlerinden oluÅŸan haÃ§lÄ± ordusunun baÅŸÄ±nda SÄ±rp KralÄ± I.LayoÅŸ vardÄ±.\n",
        "    HaÃ§lÄ± ordusu, HacÄ± Ä°lbeyi tarafÄ±ndan yapÄ±lan ani bir baskÄ±n ile yok edilmiÅŸtir.\n",
        "    SÄ±rpsÄ±ndÄ±ÄŸÄ± savaÅŸÄ±ndan sonra Edirne baÅŸkent yapÄ±lmÄ±ÅŸtÄ±r.\n",
        "    SÄ±rpsÄ±ndÄ±ÄŸÄ± savaÅŸÄ± OsmanlÄ±larÄ±n Balkanlarda haÃ§lÄ±larla yaptÄ±ÄŸÄ± ilk savaÅŸtÄ±r.\n",
        "    Bulgar krallÄ±ÄŸÄ± SÄ±rpsÄ±ndÄ±ÄŸÄ± savaÅŸÄ± sonrasÄ± OsmanlÄ± Devletine baÄŸlanmÄ±ÅŸtÄ±r.\n",
        "    1371 yÄ±lÄ±nda Ã‡irmen savaÅŸÄ± gerÃ§ekleÅŸti. Ã‡irmen savaÅŸÄ± Evranos Bey ile SÄ±rplar arasÄ±nda olmuÅŸtur. Ã‡irmen SavaÅŸÄ±nÄ± OsmanlÄ± Devleti kazanmÄ±ÅŸtÄ±r.\n",
        "    Ã‡irmen savaÅŸÄ± sonucunda Makedonya'nÄ±n bir kÄ±smÄ± alÄ±ndÄ±.\"\"\"\n",
        "ask_question(question,context)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SÄ±rpsÄ±ndÄ±ÄŸÄ± savaÅŸÄ±'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7XqIfOyFzDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e148bff3ca0b46c4946f299bca26b67d",
            "d7f6b35cc0a747d6a66c6a3094b81d98",
            "4f72501995e94867b6a58177c17cb69e",
            "260e8e5dcb48484b9d7d7783b9cb81b5",
            "5bb70d5bf5504de2b601ddb21a1eeb7d",
            "3fccf4b17c4c421493c7ef62246cef75",
            "edd9d1195ce04209bad3aa29cd3ca80e",
            "8ccc9121266344e9ba521f36f4c46192",
            "94d8985f7ead4b98a953699a368b6cb0",
            "fd0a1e4da8bd4c1c8009aa09a2043b91",
            "3045b7307925417ca68e1995923e9816",
            "b717fef393c945d8827245caf6821e37",
            "a84bc254ca42400e9af05aec5f578a58",
            "f71b4b04efb741ff8a586ff4ac4463a0",
            "6aa009af504c4ad88b67f1f09a0f9482",
            "ed01b169479f495bbc2d28b1c2351821",
            "6d590b85b41249f7a2f94bb6b4e598af",
            "a3229cc984454d4184ddfeb71c9798cc",
            "ac5060530b694684ba1672f4a38dd520",
            "d48a76f0880e40a89ae4130a0572ce6a",
            "1953362ea4ec4e508c88c809d95b4928",
            "701ad114db8c4ae7920610b804cd8b6d",
            "7e2d51f66a794f8f89a52e240ac281aa",
            "213c0c7e50ec44ccad09c44eb3406531",
            "808f1677e8644f8e9d83598468fd4c23",
            "c9a0b5c3ecbd4a62b31c4fb6d294115d",
            "2bb0010a422c4496b27b5e5b3394a468",
            "1a0c2ae6ab854c38b300a13a9bc80370",
            "594f1ecaf17842f188834b7dae758e9f",
            "84cdc3d798204a8a9323d65dfd6ac4cf",
            "c9e625cbbebc4ab0ad63f40c259dabde",
            "bd320da0ea3a4791a2519cbbe8932310",
            "bdd507357f7340aaa2dbb6f7708e2f99",
            "4c93cf11766e448d81a4c9e23af963da",
            "fe95f6ba43e34109a84b9dd4952bee59",
            "7f40987fe3744705be04571b70688104",
            "a8b006cf206c4f39ab1bfd6b8dfec074",
            "81cb75f8d5814d94ac30b820157578dc",
            "77eceb6e19994f289f924f178900f433",
            "630c5077738c4de18c11e52b67838dac"
          ]
        },
        "outputId": "2b0354e5-d633-4031-ced7-c6c76bdb656f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:09 - INFO - filelock -   Lock 139738508692504 acquired on /root/.cache/torch/transformers/de00d2114de85d1fbe7ae171c35b6b0118e2f7bfa9ecd55922d7bc6618439728.d465f032e0ca06e3c18d68488046720c2c4f07c049f9556caf0adf81cb7bdfb6.lock\n",
            "07/26/2020 20:43:09 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp6886k0t0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e148bff3ca0b46c4946f299bca26b67d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=473.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:09 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/config.json in cache at /root/.cache/torch/transformers/de00d2114de85d1fbe7ae171c35b6b0118e2f7bfa9ecd55922d7bc6618439728.d465f032e0ca06e3c18d68488046720c2c4f07c049f9556caf0adf81cb7bdfb6\n",
            "07/26/2020 20:43:09 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/de00d2114de85d1fbe7ae171c35b6b0118e2f7bfa9ecd55922d7bc6618439728.d465f032e0ca06e3c18d68488046720c2c4f07c049f9556caf0adf81cb7bdfb6\n",
            "07/26/2020 20:43:09 - INFO - filelock -   Lock 139738508692504 released on /root/.cache/torch/transformers/de00d2114de85d1fbe7ae171c35b6b0118e2f7bfa9ecd55922d7bc6618439728.d465f032e0ca06e3c18d68488046720c2c4f07c049f9556caf0adf81cb7bdfb6.lock\n",
            "07/26/2020 20:43:09 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/config.json from cache at /root/.cache/torch/transformers/de00d2114de85d1fbe7ae171c35b6b0118e2f7bfa9ecd55922d7bc6618439728.d465f032e0ca06e3c18d68488046720c2c4f07c049f9556caf0adf81cb7bdfb6\n",
            "07/26/2020 20:43:09 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"architectures\": [\n",
            "    \"ElectraForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "07/26/2020 20:43:09 - INFO - transformers.tokenization_utils_base -   Model name 'valhalla/electra-base-discriminator-finetuned_squadv1' not found in model shortcut name list (google/electra-small-generator, google/electra-base-generator, google/electra-large-generator, google/electra-small-discriminator, google/electra-base-discriminator, google/electra-large-discriminator). Assuming 'valhalla/electra-base-discriminator-finetuned_squadv1' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "07/26/2020 20:43:09 - INFO - filelock -   Lock 139738508692504 acquired on /root/.cache/torch/transformers/6dff6cfcf5d5158789294447f218eaceeb3400e34d5da8056818a03aaa63ed26.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "07/26/2020 20:43:09 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8h98k1l6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d8985f7ead4b98a953699a368b6cb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:10 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/vocab.txt in cache at /root/.cache/torch/transformers/6dff6cfcf5d5158789294447f218eaceeb3400e34d5da8056818a03aaa63ed26.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "07/26/2020 20:43:10 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/6dff6cfcf5d5158789294447f218eaceeb3400e34d5da8056818a03aaa63ed26.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "07/26/2020 20:43:10 - INFO - filelock -   Lock 139738508692504 released on /root/.cache/torch/transformers/6dff6cfcf5d5158789294447f218eaceeb3400e34d5da8056818a03aaa63ed26.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:10 - INFO - filelock -   Lock 139739108966696 acquired on /root/.cache/torch/transformers/94e96e4fc3b8d300704e845d5ebf2c9aa77027b3cc889a912b8bec3ecba5285d.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4.lock\n",
            "07/26/2020 20:43:10 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp4fnc1izx\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d590b85b41249f7a2f94bb6b4e598af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:10 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/special_tokens_map.json in cache at /root/.cache/torch/transformers/94e96e4fc3b8d300704e845d5ebf2c9aa77027b3cc889a912b8bec3ecba5285d.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
            "07/26/2020 20:43:10 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/94e96e4fc3b8d300704e845d5ebf2c9aa77027b3cc889a912b8bec3ecba5285d.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
            "07/26/2020 20:43:10 - INFO - filelock -   Lock 139739108966696 released on /root/.cache/torch/transformers/94e96e4fc3b8d300704e845d5ebf2c9aa77027b3cc889a912b8bec3ecba5285d.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4.lock\n",
            "07/26/2020 20:43:10 - INFO - filelock -   Lock 139738508692504 acquired on /root/.cache/torch/transformers/c9d8dd05ed2da6fe24bfd86a078c0e3d320e36d4f5cd912a84c89727979a96fd.11f57497ee659e26f830788489816dbcb678d91ae48c06c50c9dc0e4438ec05b.lock\n",
            "07/26/2020 20:43:10 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp3r94wm4m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "808f1677e8644f8e9d83598468fd4c23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=48.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:11 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/tokenizer_config.json in cache at /root/.cache/torch/transformers/c9d8dd05ed2da6fe24bfd86a078c0e3d320e36d4f5cd912a84c89727979a96fd.11f57497ee659e26f830788489816dbcb678d91ae48c06c50c9dc0e4438ec05b\n",
            "07/26/2020 20:43:11 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/c9d8dd05ed2da6fe24bfd86a078c0e3d320e36d4f5cd912a84c89727979a96fd.11f57497ee659e26f830788489816dbcb678d91ae48c06c50c9dc0e4438ec05b\n",
            "07/26/2020 20:43:11 - INFO - filelock -   Lock 139738508692504 released on /root/.cache/torch/transformers/c9d8dd05ed2da6fe24bfd86a078c0e3d320e36d4f5cd912a84c89727979a96fd.11f57497ee659e26f830788489816dbcb678d91ae48c06c50c9dc0e4438ec05b.lock\n",
            "07/26/2020 20:43:11 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/vocab.txt from cache at /root/.cache/torch/transformers/6dff6cfcf5d5158789294447f218eaceeb3400e34d5da8056818a03aaa63ed26.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "07/26/2020 20:43:11 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/added_tokens.json from cache at None\n",
            "07/26/2020 20:43:11 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/special_tokens_map.json from cache at /root/.cache/torch/transformers/94e96e4fc3b8d300704e845d5ebf2c9aa77027b3cc889a912b8bec3ecba5285d.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
            "07/26/2020 20:43:11 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/tokenizer_config.json from cache at /root/.cache/torch/transformers/c9d8dd05ed2da6fe24bfd86a078c0e3d320e36d4f5cd912a84c89727979a96fd.11f57497ee659e26f830788489816dbcb678d91ae48c06c50c9dc0e4438ec05b\n",
            "07/26/2020 20:43:11 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/tokenizer.json from cache at None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:11 - INFO - transformers.modelcard -   Model card: {\n",
            "  \"caveats_and_recommendations\": {},\n",
            "  \"ethical_considerations\": {},\n",
            "  \"evaluation_data\": {},\n",
            "  \"factors\": {},\n",
            "  \"intended_use\": {},\n",
            "  \"metrics\": {},\n",
            "  \"model_details\": {},\n",
            "  \"quantitative_analyses\": {},\n",
            "  \"training_data\": {}\n",
            "}\n",
            "\n",
            "07/26/2020 20:43:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/valhalla/electra-base-discriminator-finetuned_squadv1/config.json from cache at /root/.cache/torch/transformers/de00d2114de85d1fbe7ae171c35b6b0118e2f7bfa9ecd55922d7bc6618439728.d465f032e0ca06e3c18d68488046720c2c4f07c049f9556caf0adf81cb7bdfb6\n",
            "07/26/2020 20:43:11 - INFO - transformers.configuration_utils -   Model config ElectraConfig {\n",
            "  \"architectures\": [\n",
            "    \"ElectraForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "07/26/2020 20:43:11 - INFO - filelock -   Lock 139738594959432 acquired on /root/.cache/torch/transformers/5fb628232118635dacd5ef6daa80b4fac5976ed02a8e05e650a88c32d482d889.4d5270b238ee40016eeb0c0975da2e2da6b229906da3b937b0a82561fc0210da.lock\n",
            "07/26/2020 20:43:11 - INFO - transformers.file_utils -   https://cdn.huggingface.co/valhalla/electra-base-discriminator-finetuned_squadv1/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmptcd3n0kz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdd507357f7340aaa2dbb6f7708e2f99",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435621774.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:17 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/valhalla/electra-base-discriminator-finetuned_squadv1/pytorch_model.bin in cache at /root/.cache/torch/transformers/5fb628232118635dacd5ef6daa80b4fac5976ed02a8e05e650a88c32d482d889.4d5270b238ee40016eeb0c0975da2e2da6b229906da3b937b0a82561fc0210da\n",
            "07/26/2020 20:43:17 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/5fb628232118635dacd5ef6daa80b4fac5976ed02a8e05e650a88c32d482d889.4d5270b238ee40016eeb0c0975da2e2da6b229906da3b937b0a82561fc0210da\n",
            "07/26/2020 20:43:17 - INFO - filelock -   Lock 139738594959432 released on /root/.cache/torch/transformers/5fb628232118635dacd5ef6daa80b4fac5976ed02a8e05e650a88c32d482d889.4d5270b238ee40016eeb0c0975da2e2da6b229906da3b937b0a82561fc0210da.lock\n",
            "07/26/2020 20:43:17 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/valhalla/electra-base-discriminator-finetuned_squadv1/pytorch_model.bin from cache at /root/.cache/torch/transformers/5fb628232118635dacd5ef6daa80b4fac5976ed02a8e05e650a88c32d482d889.4d5270b238ee40016eeb0c0975da2e2da6b229906da3b937b0a82561fc0210da\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/26/2020 20:43:20 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing ElectraForQuestionAnswering.\n",
            "\n",
            "07/26/2020 20:43:20 - WARNING - transformers.modeling_utils -   Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at valhalla/electra-base-discriminator-finetuned_squadv1 and are newly initialized: ['electra.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ_aOrN9F_H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IFXlJf6GJRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}