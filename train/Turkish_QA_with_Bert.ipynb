{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turkish-QA-with-Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVGIbz_Jxr-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers==2.5.1\n",
        "!pip install torch==1.5.0+cu92 torchvision==0.6.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7OyTixv0PG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC92pL7FygC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -L -O https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WviS9GV8yp4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env DATA_DIR=./data/squad \n",
        "\n",
        "# download the data\n",
        "def download_squad():\n",
        "        !wget -P $DATA_DIR https://github.com/TQuad/turkish-nlp-qa-dataset/blob/master/dev-v0.1.json\n",
        "        !wget -P $DATA_DIR https://github.com/TQuad/turkish-nlp-qa-dataset/blob/master/train-v0.1.json\n",
        "            \n",
        "download_squad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srp0mdf6zVUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmd = [\n",
        "    'python', \n",
        "#    '-m torch.distributed.launch --nproc_per_node 2', # use this to perform distributed training over multiple GPUs\n",
        "    'run_squad.py', \n",
        "    \n",
        "    '--model_type', 'bert',                            # model type (one of the list under \"Pick a Model\" above)\n",
        "    \n",
        "    '--model_name_or_path', 'bert-base-tr-qa-v1',       # specific model name of the given model type (shown, a list is here: https://huggingface.co/transformers/pretrained_models.html) \n",
        "                                                       # on first execution this initiates a download of pre-trained model weights;\n",
        "                                                       # can also be a local path to a directory with model weights\n",
        "    \n",
        "    '--output_dir', './models/bert/bbu_squad2',        # directory for model checkpoints and predictions\n",
        "    \n",
        "#    '--overwrite_output_dir',                         # use when adding output to a directory that is non-empty --\n",
        "                                                       # for instance, when training crashes midway through and you need to restart it\n",
        "    \n",
        "    '--do_train',                                      # execute the training method \n",
        "    \n",
        "    '--train_file', '$DATA_DIR/train-v0.1.json',       # provide the training data\n",
        "    \n",
        "    '--version_2_with_negative',                       # ** MUST use this flag if training on SQuAD 2.0! DO NOT use if training on SQuAD 1.1\n",
        "    \n",
        "    '--do_lower_case',                                 # ** set this flag if using an uncased model; don't use for Cased Models\n",
        "    \n",
        "    '--do_eval',                                       # execute the evaluation method on the dev set -- note: \n",
        "                                                       # if coupled with --do_train, evaluation runs after fine-tuning \n",
        "    \n",
        "    '--predict_file', '$DATA_DIR/dev-v0.1.json',       # provide evaluation data (dev set)\n",
        "    \n",
        "    '--eval_all_checkpoints',                          # evaluate the model on the dev set at each checkpoint\n",
        "    \n",
        "    '--per_gpu_eval_batch_size', '12',                 # evaluation batch size for each gpu\n",
        "    \n",
        "    '--per_gpu_train_batch_size', '12',                # training batch size for each gpu\n",
        "    \n",
        "    '--save_steps', '5000',                            # how often checkpoints (complete model snapshot) are saved \n",
        "    \n",
        "    '--threads', '8',                                  # num of CPU threads to use for converting SQuAD examples to model features\n",
        "    \n",
        "    # --- Model and Feature Hyperparameters --- \n",
        "    '--num_train_epochs', '2',                         # number of training epochs - usually 2-3 for SQuAD \n",
        "    \n",
        "    '--learning_rate', '3e-5',                         # learning rate for the default optimizer (Adam in this case)\n",
        "    \n",
        "    '--max_seq_length', '512',                         # maximum length allowed for the full input sequence \n",
        "    \n",
        "    '--doc_stride', '128'                              # used for long documents that must be chunked into multiple features -- \n",
        "       ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ4mqYcD2AWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_squad(version=1):\n",
        "    if version == 1:\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
        "    else:\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
        "            \n",
        "download_squad(version=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVPANdIyz0Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path dbmdz/bert-base-turkish-cased  \\\n",
        "    --output_dir models/bert/ \\\n",
        "    --data_dir data/squad   \\\n",
        "    --overwrite_output_dir \\\n",
        "    --overwrite_cache \\\n",
        "    --do_train  \\\n",
        "    --train_file train-v0.1-cv.json   \\\n",
        "    --version_2_with_negative \\\n",
        "    --do_eval   \\\n",
        "    --predict_file dev-v0.1-cv.json   \\\n",
        "    --per_gpu_train_batch_size 16   \\\n",
        "    --learning_rate 3e-5   \\\n",
        "    --num_train_epochs 2.0   \\\n",
        "    --max_seq_length 512   \\\n",
        "    --doc_stride 128   \\\n",
        "    --threads 10   \\\n",
        "    --save_steps 5000 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6hZUXdcMozZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./models/bert/\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"./models/bert/\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAQZsfiiNsX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1fb03df-ec04-4c25-ceea-9dec47753a77"
      },
      "source": [
        "question = \"I.Murat'ın annesi kimdir?\"\n",
        "\n",
        "context = \"\"\"I.Murat 1326 yılında Bursada doğmuştur. I.Murat 1389 yılında Kosavada ölmüştür.\n",
        "    Osmanlı İmparatorluğu'nun üçüncü padişahı olan I.Murat, 1359 ile 1389 yılları arasında beylik yapmıştır.\n",
        "    I.Murat'ın babası Orhan Gazi, annesi Nilüfer Hatun'dur.\n",
        "    I.Murat babası Orhan Gazi döneminde 95.000 kilometrekare olarak almış, devlet topraklarını I.Murat döneminde topraklarını yaklaşık 500.000 kilometrekareye genişlemiştir.\n",
        "    1362 yılında Ankara Eratna beyliğinden yeniden alınmıştır.\n",
        "    1362 yılında Sazlıdere savaşı ile gerçekleşmiştir. Sazlıdere savaşı sonucunda Edirne ve Filibe alınmıştır. Sazlıdere savaşı Osmanlı devleti ile Bizans ve Bulgar güçleri arasında gerçekleşmiştir.\n",
        "    Hamitoğullarından Eğridir ve çevresi satın alındı.\n",
        "    1364 yılında Sırpsındığı savaşı gerçekleşti. Balkan devletlerinden oluşan haçlı ordusunun başında Sırp Kralı I.Layoş vardı.\n",
        "    Haçlı ordusu, Hacı İlbeyi tarafından yapılan ani bir baskın ile yok edilmiştir.\n",
        "    Sırpsındığı savaşından sonra Edirne başkent yapılmıştır.\n",
        "    Sırpsındığı savaşı Osmanlıların Balkanlarda haçlılarla yaptığı ilk savaştır.\n",
        "    Bulgar krallığı Sırpsındığı savaşı sonrası Osmanlı Devletine bağlanmıştır.\n",
        "    1371 yılında Çirmen savaşı gerçekleşti. Çirmen savaşı Evranos Bey ile Sırplar arasında olmuştur. Çirmen Savaşını Osmanlı Devleti kazanmıştır.\n",
        "    Çirmen savaşı sonucunda Makedonya'nın bir kısmı alındı.\"\"\"\n",
        "\n",
        "\n",
        " \n",
        "inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\") \n",
        "\n",
        "\n",
        "answer_start_scores, answer_end_scores = model(**inputs)\n",
        "answer_start = torch.argmax(answer_start_scores)  \n",
        "answer_end = torch.argmax(answer_end_scores) + 1  \n",
        "\n",
        "\n",
        "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nilüfer Hatun'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}